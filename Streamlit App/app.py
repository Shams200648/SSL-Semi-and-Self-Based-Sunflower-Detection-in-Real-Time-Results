import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from ultralytics import YOLO
from pathlib import Path
from PIL import Image
import os
import cv2
import tempfile
import time

# =====================
# Paths
# =====================
RUNS_DIR = Path("D:/EWU/10th Semester/CSE475/LABS/Project/Streamlit App/runs_ssl")
st.set_page_config(page_title="Sunflower SSL Dashboard", layout="wide")
st.title("üåª Sunflower Image Detection in Real-Time Dashboard")

# =====================
# Sidebar
# =====================
st.sidebar.title("‚öôÔ∏è Dashboard Controls")
st.sidebar.subheader("üß™ Experiment Settings")

exp_dirs = [d for d in RUNS_DIR.iterdir() if d.is_dir()]
custom_labels = [
    "BYOL-YOLOv10s", "BYOL-YOLOv11s", "BYOL-YOLOv12s",
    "PSEUDO-STACK-(10-90)", "PSEUDO-STACK-(20-80)", "PSEUDO-STACK-(30-70)",
    "PSEUDO-STACK-(40-60)",
    "DINO-YOLOv10s", "DINO-YOLOv11s", "DINO-YOLOv12s"
]
exp_choice_label = st.sidebar.selectbox("üåü Choose SSL Experiment", custom_labels)
exp_choice = exp_dirs[custom_labels.index(exp_choice_label)]

best_model_path = exp_choice / "weights" / "best.pt"
results_csv = exp_choice / "results.csv"
results_png = exp_choice / "results.png"

st.sidebar.subheader("ü§ñ Model Configuration")
st.sidebar.markdown(f"**Experiment:** {exp_choice_label}")

st.sidebar.subheader("üîç Prediction Settings")
conf_threshold = st.sidebar.slider("Confidence Threshold", 0.1, 1.0, 0.25, 0.05)

# Subsection for detection vs plots
st.sidebar.subheader("üìÇ Dashboard View")
view_choice = st.sidebar.radio("Choose View", ["Detections", "Plots", "Arm Control"])


# =====================
# Load model
# =====================
@st.cache_resource
def load_model(model_path):
    return YOLO(str(model_path))

model = load_model(best_model_path)

# =====================
# Detections (Image/Video/Live Camera)
# =====================
if view_choice == "Detections":
    st.subheader("üîç Test Your Model on a Custom Image/Video")
    st.markdown(f"**Using Model:** `{exp_choice_label}`")

    uploaded_file = st.file_uploader("Upload an image or video", type=["jpg","jpeg","png","mp4"])
    preds_dir = exp_choice / "preds"
    os.makedirs(preds_dir, exist_ok=True)

    if uploaded_file is not None:
        file_ext = uploaded_file.name.split('.')[-1].lower()
        temp_path = Path(tempfile.mkdtemp()) / uploaded_file.name
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.read())

        if file_ext in ["jpg","jpeg","png"]:
            img = Image.open(temp_path).convert("RGB")
            results = model.predict(source=img, conf=conf_threshold, verbose=False)
            annotated_img = results[0].plot(line_width=1, font_size=5)

            col1, col2 = st.columns(2)
            with col1:
                st.image(img, caption="Uploaded Image", width=600)
            with col2:
                st.image(annotated_img[:, :, ::-1], caption="Annotated Result", width=600)

            save_path = preds_dir / uploaded_file.name
            Image.fromarray(annotated_img[:, :, ::-1]).save(save_path)
            with open(save_path, "rb") as f:
                st.download_button("üíæ Download Annotated Image", f, file_name=uploaded_file.name, mime="image/png")

        elif file_ext == "mp4":
            cap = cv2.VideoCapture(str(temp_path))
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

            file_stem = Path(uploaded_file.name).stem
            annotated_video_path = preds_dir / f"annotated_{file_stem}.mp4"

            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(str(annotated_video_path), fourcc, fps, (width, height))

            frame_count = 0
            progress_bar = st.progress(0)
            progress_text = st.empty()
            frame_placeholder = st.empty()
            start_time = time.time()

            with st.spinner("Processing video and generating annotations..."):
                while True:
                    ret, frame = cap.read()
                    if not ret:
                        break

                    results = model.predict(frame, conf=conf_threshold, verbose=False)
                    annotated_frame = results[0].plot(line_width=1, font_size=4)
                    out.write(annotated_frame[:, :, ::-1])

                    frame_placeholder.image(annotated_frame[:, :, ::-1], channels="RGB", width=1000)

                    frame_count += 1
                    if total_frames > 0:
                        progress = int((frame_count / total_frames) * 100)
                        progress_bar.progress(progress)
                        elapsed = time.time() - start_time
                        remaining = max(0, int((elapsed / frame_count) * (total_frames - frame_count)))
                        progress_text.markdown(
                            f"Processing frame {frame_count}/{total_frames} | Estimated time left: {remaining}s"
                        )

            cap.release()
            out.release()
            progress_bar.empty()
            progress_text.empty()
            frame_placeholder.empty()
            st.success("‚úÖ Video annotation complete!")

            with open(annotated_video_path, "rb") as f:
                st.download_button(
                    "üíæ Download Annotated Video",
                    f,
                    file_name=f"annotated_{file_stem}.mp4",
                    mime="video/mp4"
                )

    # Live Camera
    st.subheader("üì∑ Live Camera Detection (Target: 30 FPS)")

    st.sidebar.subheader("üé• Camera Source")
    camera_type = st.sidebar.radio(
        "Select Camera",
        ["Laptop Webcam", "External USB Webcam", "Mobile Camera (IP/RTSP)"]
    )

    mobile_url = None
    if camera_type == "Mobile Camera (IP/RTSP)":
        mobile_url = st.sidebar.text_input(
            "Enter Camera URL (e.g., http://192.168.0.101:8080/video)",
            value="http://192.168.0.101:8080/video"
        )
        if st.sidebar.button("üîç Test Camera URL"):
            cap_test = cv2.VideoCapture(mobile_url)
            ret, frame = cap_test.read()
            if ret:
                st.sidebar.success("‚úÖ Camera is reachable!")
                st.sidebar.image(frame[:, :, ::-1], channels="RGB", width=300)
            else:
                st.sidebar.error("‚ùå Could not reach the camera. Check URL or network.")
            cap_test.release()

    start_cam = st.button("‚ñ∂Ô∏è Start Live Camera")

    if start_cam:
        if camera_type == "Laptop Webcam":
            cap = cv2.VideoCapture(0)
        elif camera_type == "External USB Webcam":
            cap = cv2.VideoCapture(1)
        elif camera_type == "Mobile Camera (IP/RTSP)" and mobile_url:
            cap = cv2.VideoCapture(mobile_url)
        else:
            st.error("‚ùå Please provide a valid camera URL or device")
            cap = None

        if cap and cap.isOpened():
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            cap.set(cv2.CAP_PROP_FPS, 30)

            col1, col2 = st.columns([2, 1])
            with col1:
                frame_placeholder = st.empty()
            with col2:
                stop_cam = st.button("‚èπÔ∏è Stop Camera")
                fps_text = st.empty()

            prev_time = time.time()

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    st.warning("‚ö†Ô∏è Could not read frame. Check camera or URL.")
                    break

                frame = cv2.resize(frame, (640, 480))
                results = model(frame, stream=True, conf=conf_threshold, verbose=False)
                for r in results:
                    annotated_frame = r.plot(line_width=2, font_size=12)

                curr_time = time.time()
                fps = 1 / (curr_time - prev_time)
                prev_time = curr_time

                frame_placeholder.image(
                    annotated_frame[:, :, ::-1], channels="RGB", width=600
                )
                fps_text.markdown(f"**FPS:** {fps:.1f}")

                elapsed = time.time() - curr_time
                wait_time = max(0, (1/30) - elapsed)
                time.sleep(wait_time)

                if stop_cam:
                    break

            cap.release()
            st.success("‚úÖ Camera stopped")

# =====================
# Plots (Training Performance)
# =====================
elif view_choice == "Plots":
    st.subheader("üìà Training Performance Overview")
    if results_csv.exists():
        df = pd.read_csv(results_csv)
        col1, col2 = st.columns(2)
        col3, col4 = st.columns(2)

        small_figsize = (8,4)

        with col1:
            fig, ax = plt.subplots(figsize=small_figsize)
            if "epoch" in df.columns and "train/box_loss" in df.columns and "val/box_loss" in df.columns:
                ax.plot(df["epoch"], df["train/box_loss"], label="Train Box Loss")
                ax.plot(df["epoch"], df["val/box_loss"], label="Val Box Loss")
                ax.set_xlabel("Epoch"); ax.set_ylabel("Loss")
                ax.set_title("Train vs Val Box Loss")
                ax.legend(); ax.grid(True)
                st.pyplot(fig)

        with col2:
            loss_cols = ["epoch", "train/box_loss","train/cls_loss","val/box_loss","val/cls_loss"]
            if all(col in df.columns for col in loss_cols):
                fig2, ax2 = plt.subplots(figsize=small_figsize)
                ax2.plot(df["epoch"], df["train/box_loss"], label="Train Box Loss", linewidth=2)
                ax2.plot(df["epoch"], df["train/cls_loss"], label="Train Class Loss", linewidth=2)
                ax2.plot(df["epoch"], df["val/box_loss"], label="Val Box Loss", linestyle="--")
                ax2.plot(df["epoch"], df["val/cls_loss"], label="Val Class Loss", linestyle="--")
                ax2.set_xlabel("Epoch"); ax2.set_ylabel("Loss"); ax2.set_title("Detailed Train/Val Loss")
                ax2.legend(); ax2.grid(True)
                st.pyplot(fig2)

        with col3:
            lr_columns = [col for col in df.columns if col.startswith("lr/pg")]
            if lr_columns:
                fig3, ax3 = plt.subplots(figsize=small_figsize)
                colors = ['purple','orange','green']; styles=['-','--','-.']; markers=['o','s','^']
                for idx,col in enumerate(lr_columns):
                    ax3.plot(df["epoch"], df[col], label=col, color=colors[idx%3], linestyle=styles[idx%3],
                            marker=markers[idx%3], markersize=4, linewidth=2)
                ax3.set_xlabel("Epoch"); ax3.set_ylabel("Learning Rate"); ax3.set_title("Learning Rates")
                ax3.legend(); ax3.grid(True)
                st.pyplot(fig3)

        with col4:
            map_keys = ["metrics/mAP50(B)","metrics/mAP50-95(B)"]
            map_col = next((k for k in map_keys if k in df.columns), None)
            if map_col:
                fig4, ax4 = plt.subplots(figsize=small_figsize)
                ax4.plot(df["epoch"], df[map_col], label=map_col, color="green", linewidth=2)
                ax4.set_xlabel("Epoch"); ax4.set_ylabel("mAP"); ax4.set_title("mAP During Training")
                ax4.grid(True); ax4.legend(); st.pyplot(fig4)

    st.subheader("üñºÔ∏è Results Image")
    if results_png.exists():
        img = Image.open(results_png)
        st.image(img, caption="Results Image", use_container_width=True)

elif view_choice == "Arm Control":
    st.subheader("ü§ñ xArm 1S Manual Control (Streamlit Version with Torque Control)")

    import xarm

    class XArmGUI:
        def __init__(self):
            self.robot = self.connect_to_robot()
            if self.robot is None:
                st.error("Exiting application due to connection failure.")
                st.stop()
            st.success("xArm connected Successfully")

            # Default values per joint
            default_values = {
                "gripper": 500,
                "link2": 500,
                "link3": 250,
                "link4": 820,
                "link5": 640,
                "link6": 500,
                "torque_gripper": 500,
                "torque_link2": 500,
                "torque_link3": 500,
                "torque_link4": 500,
                "torque_link5": 500,
                "torque_link6": 500,
            }

            # Initialize session state only if keys do not exist
            for key, value in default_values.items():
                st.session_state.setdefault(key, value)

            # Columns for sliders
            col1, col2, col3 = st.columns([2, 2, 1])

            # Reset button in column 3
            with col3:
                if st.button("üîÑ Reset to Default"):
                    for key, value in default_values.items():
                        st.session_state[key] = value
                    st.rerun()  # Rerun so sliders update visually
                    st.info("‚úÖ Sliders reset to default")

            # Position sliders in col1
            with col1:
                st.slider("Gripper Position", 0, 1000, st.session_state.gripper, key="gripper")
                st.slider("Link 2 Position", 0, 1000, st.session_state.link2, key="link2")
                st.slider("Link 3 Position", 0, 1000, st.session_state.link3, key="link3")
                st.slider("Link 4 Position", 0, 1000, st.session_state.link4, key="link4")
                st.slider("Link 5 Position", 0, 1000, st.session_state.link5, key="link5")
                st.slider("Link 6 Position", 0, 1000, st.session_state.link6, key="link6")

            # Torque sliders in col2
            with col2:
                st.slider("Gripper Torque", 0, 1000, st.session_state.torque_gripper, key="torque_gripper")
                st.slider("Link 2 Torque", 0, 1000, st.session_state.torque_link2, key="torque_link2")
                st.slider("Link 3 Torque", 0, 1000, st.session_state.torque_link3, key="torque_link3")
                st.slider("Link 4 Torque", 0, 1000, st.session_state.torque_link4, key="torque_link4")
                st.slider("Link 5 Torque", 0, 1000, st.session_state.torque_link5, key="torque_link5")
                st.slider("Link 6 Torque", 0, 1000, st.session_state.torque_link6, key="torque_link6")

            # Update arm continuously
            self.send_val()

        def send_val(self):
            positions = [
                st.session_state.gripper,
                st.session_state.link2,
                st.session_state.link3,
                st.session_state.link4,
                st.session_state.link5,
                st.session_state.link6,
            ]
            torques = [
                st.session_state.torque_gripper,
                st.session_state.torque_link2,
                st.session_state.torque_link3,
                st.session_state.torque_link4,
                st.session_state.torque_link5,
                st.session_state.torque_link6,
            ]

            # Adjust duration based on torque (more torque = faster motion)
            min_duration = 0.05
            max_duration = 2.0
            for i, (pos, tq) in enumerate(zip(positions, torques), start=1):
                duration = max_duration - ((tq / 1000) * (max_duration - min_duration))
                self.robot.setPosition(i, pos, int(duration * 1000), wait=False)

        def connect_to_robot(self):
            try:
                robot = xarm.Controller('USB')
                st.info("Connected to xArm robot.")
                return robot
            except Exception as e:
                st.error(f"Failed to connect to xArm robot: {e}")
                return None
    gui = XArmGUI()





# elif view_choice == "Arm Control":
#     st.subheader("ü§ñ xArm 1S Automated Control (Streamlit Version)")

#     import streamlit as st
#     import xarm
#     import time
#     import random  # For demo automation (replace with your own logic or camera input)

#     class XArmAutoGUI:
#         def __init__(self):
#             self.robot = self.connect_to_robot()
#             if self.robot is None:
#                 st.error("Exiting due to connection failure.")
#                 st.stop()
#             st.success("‚úÖ xArm connected successfully")

#             # Default servo positions and torque
#             self.positions = [500]*6
#             self.torques = [500]*6

#             # Columns for info
#             col1, col2, col3 = st.columns([2,2,1])

#             # Reset button in col3
#             with col3:
#                 if st.button("üîÑ Reset to Default"):
#                     self.positions = [500]*6
#                     self.torques = [500]*6
#                     st.info("‚úÖ Positions & Torque reset to 500")

#             # Display current positions and torque in col1 & col2
#             with col1:
#                 st.write("### Current Positions")
#                 for i, pos in enumerate(self.positions, start=1):
#                     st.text(f"Link {i}: {pos}")

#             with col2:
#                 st.write("### Current Torque")
#                 for i, tq in enumerate(self.torques, start=1):
#                     st.text(f"Link {i}: {tq}")

#             # Run automated update loop
#             self.run_automation()

#         def run_automation(self):
#             st.write("### Automated Arm Control Running...")
#             placeholder = st.empty()  # placeholder to show dynamic values
#             while True:
#                 # Example automated logic:
#                 # You can replace this with camera detection or AI output
#                 for i in range(6):
#                     self.positions[i] = random.randint(200, 800)
#                     self.torques[i] = random.randint(200, 800)

#                 # Update robot positions
#                 self.send_val()

#                 # Update Streamlit display
#                 placeholder.text(f"Positions: {self.positions}\nTorque: {self.torques}")

#                 # Update every 0.1 sec
#                 time.sleep(0.1)

#         def send_val(self):
#             min_duration = 0.05
#             max_duration = 2.0
#             for i, (pos, tq) in enumerate(zip(self.positions, self.torques), start=1):
#                 duration = max_duration - ((tq / 1000) * (max_duration - min_duration))
#                 self.robot.setPosition(i, pos, int(duration*1000), wait=False)

#         def connect_to_robot(self):
#             try:
#                 robot = xarm.Controller('USB')
#                 st.info("Connected to xArm robot")
#                 return robot
#             except:
#                 st.error("Failed to connect to xArm robot")
#                 return None

#     gui = XArmAutoGUI()